[{"authors":["admin"],"categories":null,"content":"Computer vision wizard and surfer from Portugal. Currently, I am working as a Research Fellow for the Future AI and Robotics for Space Hub, developing visual perception methods for on-orbit robotic operations. I did my PhD on Probabilistic Visual Odometry using RGB-D and Geometric primitives for Man-made Environments. I am particularly interested in modelling uncertainty and using multiple view geometry, deep learning and computer graphics to solve computer vision problems. ","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://pedropro.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"Computer vision wizard and surfer from Portugal. Currently, I am working as a Research Fellow for the Future AI and Robotics for Space Hub, developing visual perception methods for on-orbit robotic operations. I did my PhD on Probabilistic Visual Odometry using RGB-D and Geometric primitives for Man-made Environments. I am particularly interested in modelling uncertainty and using multiple view geometry, deep learning and computer graphics to solve computer vision problems. ","tags":null,"title":"Pedro F. Proença","type":"authors"},{"authors":[],"categories":[],"content":"URSO (Unreal Rendered Spacecraft On-Orbit) is a simulator built on Unreal Engine 4 to render photorealistic images of spacecrafts orbiting the earth, that can be used to learn and evaluate spacecraft pose estimation, tracking and detection algorithms.  Spacecraft pose estimation is an important task to on-orbit proximity maneuvers in rendezvous/docking and servicing operations, but also future space debris removal missions. While this has been mostly addressed by using classic computer vision techniques based on edge-models, these methods are not robust to the challenging lighting conditions of space and the earth background. Therefore, I have been training instead deep learning models on URSO datasets for these tasks and investigating how to better transfer these to real space imagery. Below, you can see some results of these experiments.  ","date":1559324272,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559324272,"objectID":"64792e7cb46bace6ebeb73f44f65a5dd","permalink":"https://pedropro.github.io/project/urso/","publishdate":"2019-05-31T18:37:52+01:00","relpermalink":"/project/urso/","section":"project","summary":"Photorealistic rendering and deep learning for spacecraft pose estimation","tags":[],"title":"URSO","type":"project"},{"authors":[],"categories":[],"content":" Coming Soon   -- ","date":1559324272,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559324272,"objectID":"315db3d63dcd25c2c2d258a47b3e59ed","permalink":"https://pedropro.github.io/project/vo/","publishdate":"2019-05-31T18:37:52+01:00","relpermalink":"/project/vo/","section":"project","summary":"Visual Odometry for Man-made Environments","tags":[],"title":"Visual Odometry","type":"project"},{"authors":["Pedro F. Proença","Yang Gao"],"categories":[],"content":"","date":1546263190,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546263190,"objectID":"75593b7ada6ff48e4410e9abaac7b0f7","permalink":"https://pedropro.github.io/publication/cape/","publishdate":"2019-05-31T14:33:10+01:00","relpermalink":"/publication/cape/","section":"publication","summary":"This paper presents CAPE, a method to extract planes and cylinder segments from organized point clouds, which processes 640 × 480 depth images on a single CPU core at an average of 300 Hz, by operating on a grid of planar cells. While, compared to state-of-the-art plane extraction, the latency of CAPE is more consistent and 4-10 times faster, depending on the scene, we also demonstrate empirically that applying CAPE to visual odometry can improve trajectory estimation on scenes made of cylindrical surfaces (e.g. tunnels), whereas using a plane extraction approach that is not curve-aware deteriorates performance on these scenes. To use these geometric primitives in visual odometry, we propose extending a probabilistic RGB-D odometry framework based on points, lines and planes to cylinder primitives. Following this framework, CAPE runs on fused depth maps and the parameters of cylinders are modelled probabilistically to account for uncertainty and weight accordingly the pose optimization residuals.","tags":[],"title":"Fast Cylinder and Plane Extraction from Depth Cameras for Visual Odometry","type":"publication"},{"authors":[],"categories":[],"content":" Coming Soon   -- ","date":1527788272,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1527788272,"objectID":"d5f6eea540eb905b5dd07a5cc3aee342","permalink":"https://pedropro.github.io/project/taco/","publishdate":"2018-05-31T18:37:52+01:00","relpermalink":"/project/taco/","section":"project","summary":"Trash Annotations in Context Dataset","tags":[],"title":"TACO","type":"project"},{"authors":["Pedro F. Proença","Yang Gao"],"categories":[],"content":"","date":1520688790,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1520688790,"objectID":"829a556dc7520e894031c12f34edaf21","permalink":"https://pedropro.github.io/publication/ras_18_paper/","publishdate":"2018-03-10T14:33:10+01:00","relpermalink":"/publication/ras_18_paper/","section":"publication","summary":"This paper presents CAPE, a method to extract planes and cylinder segments from organized point clouds, which processes 640 × 480 depth images on a single CPU core at an average of 300 Hz, by operating on a grid of planar cells. While, compared to state-of-the-art plane extraction, the latency of CAPE is more consistent and 4-10 times faster, depending on the scene, we also demonstrate empirically that applying CAPE to visual odometry can improve trajectory estimation on scenes made of cylindrical surfaces (e.g. tunnels), whereas using a plane extraction approach that is not curve-aware deteriorates performance on these scenes. To use these geometric primitives in visual odometry, we propose extending a probabilistic RGB-D odometry framework based on points, lines and planes to cylinder primitives. Following this framework, CAPE runs on fused depth maps and the parameters of cylinders are modelled probabilistically to account for uncertainty and weight accordingly the pose optimization residuals.","tags":[],"title":"Probabilistic RGB-D Odometry based on Points, Lines and Planes Under Depth Uncertainty","type":"publication"},{"authors":["Pedro F. Proença","Yang Gao"],"categories":[],"content":"","date":1513258390,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1513258390,"objectID":"62595e52ccfe5a0b5a783efca92b693e","permalink":"https://pedropro.github.io/publication/splode/","publishdate":"2019-05-31T14:33:10+01:00","relpermalink":"/publication/splode/","section":"publication","summary":"Active depth cameras suffer from several limitations, which cause incomplete and noisy depth maps, and may consequently affect the performance of RGB-D Odometry. To address this issue, this paper presents a visual odometry method based on point and line features that leverages both measurements from a depth sensor and depth estimates from camera motion. Depth estimates are generated continuously by a probabilistic depth estimation framework for both types of features to compensate for the lack of depth measurements and inaccurate feature depth associations. The framework models explicitly the uncertainty of triangulating depth from both point and line observations to validate and obtain precise estimates. Furthermore, depth measurements are exploited by propagating them through a depth map registration module and using a frame-to-frame motion estimation method that considers 3D-to-2D and 2D-to-3D reprojection errors, independently. Results on RGB-D sequences captured on large indoor and outdoor scenes, where depth sensor limitations are critical, show that the combination of depth measurements and estimates through our approach is able to overcome the absence and inaccuracy of depth measurements.","tags":[],"title":"SPLODE: Semi-Probabilistic Point and Line Odometry with Depth Estimation from RGB-D Camera Motion","type":"publication"}]